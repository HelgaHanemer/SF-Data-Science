# CVD Prediction — ноутбук проекта

Учебный проект решает задачу бинарной классификации риска сердечно-сосудистого заболевания по табличным данным.  
Мы оптимизировали память/скорость, сделали прозрачный EDA, построили несколько моделей и оформили краткие выводы после каждого шага.

---

## Содержание
1. [Данные и цель](#Данные-и-цель)
2. [Стек и требования](#Стек-и-требования)
3. [Как запустить](#Как-запустить)
4. [Пайплайн ноутбука](#Пайплайн-ноутбука)
5. [EDA — основные наблюдения](#EDA--основные-наблюдения)
6. [Модели и результаты](#Модели-и-результаты)
7. [Инференс и `submission.csv`](#Инференс-и-submissioncsv)
8. [Оптимизации по памяти и времени](#Оптимизации-по-памяти-и-времени)
9. [Что дальше](#Что-дальше)

---

## Данные и цель
- **Размеры**: `train` ≈ **600 000** строк, `test` ≈ **400 000** строк, ~14 признаков + целевая `class` (в `train`).  
- **Цель**: предсказать вероятность/класс наличия ССЗ (`class ∈ {0,1}`) и сформировать `submission.csv` для теста.

---

## Стек и требования
- Python ≥ 3.10
- `pandas`, `numpy`, `scipy`
- `scikit-learn` ≥ 1.4 (важно: у `OneHotEncoder` параметр **`sparse_output`**, а не `sparse`)
- `matplotlib` / `seaborn`
- `joblib`
- `torch` (PyTorch) — для варианта с нейросетью

---

## Как запустить
1. Откройте тетрадь в VS Code / Jupyter.
2. Убедитесь, что папка `checkpoints/` доступна на запись.
3. Выполните **Run All**. По завершении сформируется `submission.csv`.

---

## Пайплайн ноутбука

1. **Загрузка данных.**  
2. **Приведение типов (даункаст):**
   - `float64 → float32`, `int64 → int32/16`, категориальные — компактные `int8`.
   - Существенная экономия памяти (например, `train` ~ **24.6 MB**).
   - После шага — «Краткий вывод по типам».
3. **Проверка и фильтрация невалидных значений** (разумные границы для возрастов, давлений, холестерина и т.п.).  
   Отчёт: сколько строк удалено/оставлено.
4. **EDA**:
   - распределения, boxplot’ы, scatter (например, `age` vs `serum_cholestoral`), матрица корреляций;
   - **после каждого графика** — краткий вывод с числами (доля выбросов, max |r|, средние по классам и т.д.).
5. **Разбиение train/validation** (`train_test_split` со стратификацией).  
   Выводятся размеры и доля положительного класса в частях.
6. **Препроцессинг признаков (канонический):**
   - `OneHotEncoder(handle_unknown="ignore", sparse_output=True, dtype=float32, max_categories=100)` для категориальных;
   - `MaxAbsScaler` для числовых;
   - `ColumnTransformer(sparse_threshold=1.0)` — сохраняем **разреженный** формат.
7. **Модели**:
   - Logistic Regression (`Pipeline(preprocess→clf)`).
   - RandomForest (ускорённый пресет для больших данных).
   - Нейронная сеть (PyTorch, MLP) поверх трансформированных признаков.
   - После каждой модели — расчёт метрик и **Markdown-вывод**.

---

## EDA — основные наблюдения
- **Типы приведены корректно**: числовые — `float32`/`int32`; категориальные — `int8`.
- **Фильтрация**: удаление явных невалидов по разумным порогам (в некоторых наборах — 0 удалённых строк).
- **Корреляции**: сильной мультиколлинеарности нет, преобладают умеренные связи.
- **Scatter `age` vs `serum_cholestoral`**: линейная связь слабая; у класса 1 средний холестерин выше.
- **Boxplot**: умеренные выбросы присутствуют; распределения асимметричны.

---

## Модели и результаты (валидация)

### Logistic Regression
- **Accuracy ≈ 0.887**
- **Precision ≈ 0.878**
- **Recall ≈ 0.866**
- **F1 ≈ 0.872**
- **ROC-AUC ≈ 0.954**
- **Вывод:** очень сильный ранжирующий бэйзлайн при минимальной сложности.

### Random Forest (ускорённый пресет)
- Конфиг: `n_estimators=120`, `max_depth=12`, `min_samples_leaf=100`, `max_samples=200_000`, `n_jobs=1`, `verbose=1`.
- **Смысл пресета:** резко ускоряет обучение на больших данных при умеренной потере качества.
- **Вывод:** на этих данных RF сопоставим с линейной моделью; без тюнинга не превосходит LR/НС.

### Нейронная сеть (MLP, 3 эпохи)
- **Accuracy ≈ 0.884**
- **Precision ≈ 0.875**
- **Recall ≈ 0.863**
- **F1 ≈ 0.869**
- **ROC-AUC ≈ 0.952**
- **Вывод:** качество **сопоставимо** с логистической регрессией (ΔROC-AUC ≈ −0.002). Потенциал роста — тюнинг архитектуры/эпох, регуляризация, early stopping.

> В ноутбуке под метриками каждой модели вставлен соответствующий «Краткий вывод».

---

## Инференс и `submission.csv`
- Инференс читает `checkpoints/best_model.which` (`logreg` / `rf` / `nn`) и подгружает:
  - классические модели: `best_model.joblib` (с препроцессором внутри),
  - НС: веса `best_model.pt` + препроцессор (`pre_nn.joblib`) или фоллбэк на числовые.
- Защита от отсутствия `ID` в тесте: при необходимости генерируется последовательный ID.
- На выходе — **`submission.csv`** со столбцами `ID, class`.

---

## Оптимизации по памяти и времени
- `OneHotEncoder(sparse_output=True, dtype=float32, max_categories=100)` — сохраняем разреженность и ограничиваем кардинальность.
- `MaxAbsScaler` — сохраняет разреженность (вместо `StandardScaler(with_mean=True)`).
- Для RF: подвыборка (`max_samples`) и ограниченная глубина; `n_jobs=1` на Windows уменьшает накладные расходы.
- Для НС: денсификация только подмножества (например, 120k строк) перед обучением; валидация — батчами.

---

## Что дальше
- Тюнинг порога по целевой метрике (если требуется метрика по классам).
- Больше эпох / early stopping / weight decay / dropout для НС; эмбеддинги для категориальных.
- Сравнить с градиентным бустингом (CatBoost / LightGBM / XGBoost) — часто сильные на табличных.
- Калибровка вероятностей (Platt/Isotonic), если нужна корректность вероятностей.

---

### Итог
- Данные очищены и оптимизированы по типам; пайплайн воспроизводим.  
- LR дала **ROC-AUC ~ 0.954** и остаётся сильным, простым бэйзлайном.  
- НС показывает **сопоставимое** качество (**ROC-AUC ~ 0.952**).  
- RF на ускорённом пресете удобен как быстрый ансамблевый ориентир.  
- Инференс устойчивый: `submission.csv` формируется надёжно при разных артефактах.

